{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Carrier Megaline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been observed that many subscribers are still utilizing older legacy plans, prompting Megaline's interest in transitioning them to newer, more advanced plans: Smart or Ultra.\n",
    "\n",
    "The objective is to utilize subscriber behavior data, particularly from those who have already migrated to the new plans, and construct a sophisticated model capable of analyzing this data to recommend the most suitable plan—either Smart or Ultra—for each subscriber.\n",
    "\n",
    "The initial groundwork has been established through extensive data preprocessing efforts undertaken in a prior project on Statistical Data Analysis. With this preprocessing completed, the project is poised to advance into the development phase of creating the model.\n",
    "\n",
    "The overarching goal is to develop a model that achieves the highest achievable accuracy. Megaline has set a challenging threshold of 75% accuracy for this project, with a determination to meet and exceed this target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset was loaded succesfulyy!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"../data/users_behavior.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"The following error: ({e}) occured while trying to load the dataset\")\n",
    "else:\n",
    "    print(f\"The dataset was loaded succesfulyy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.0</td>\n",
       "      <td>560.51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9619.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.0</td>\n",
       "      <td>344.32</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19898.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51.0</td>\n",
       "      <td>437.13</td>\n",
       "      <td>61.0</td>\n",
       "      <td>21523.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56.0</td>\n",
       "      <td>433.07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16702.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108.0</td>\n",
       "      <td>587.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14406.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>22.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2710.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>588.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26.0</td>\n",
       "      <td>163.62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16870.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>79.0</td>\n",
       "      <td>532.62</td>\n",
       "      <td>90.0</td>\n",
       "      <td>19908.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49.0</td>\n",
       "      <td>341.67</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11770.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    calls  minutes  messages   mb_used  is_ultra\n",
       "0    40.0   311.90      83.0  19915.42         0\n",
       "1    85.0   516.75      56.0  22696.96         0\n",
       "2    77.0   467.66      86.0  21060.45         0\n",
       "3   106.0   745.53      81.0   8437.39         1\n",
       "4    66.0   418.74       1.0  14502.75         0\n",
       "5    58.0   344.56      21.0  15823.37         0\n",
       "6    57.0   431.64      20.0   3738.90         1\n",
       "7    15.0   132.40       6.0  21911.60         0\n",
       "8     7.0    43.39       3.0   2538.67         1\n",
       "9    90.0   665.41      38.0  17358.61         0\n",
       "10   82.0   560.51      20.0   9619.53         1\n",
       "11   45.0   344.32      13.0  19898.81         0\n",
       "12   51.0   437.13      61.0  21523.58         0\n",
       "13   56.0   433.07      16.0  16702.36         0\n",
       "14  108.0   587.90       0.0  14406.50         1\n",
       "15    6.0    22.13       0.0   2710.09         0\n",
       "16    2.0    18.73       0.0    588.89         0\n",
       "17   26.0   163.62       4.0  16870.34         0\n",
       "18   79.0   532.62      90.0  19908.31         0\n",
       "19   49.0   341.67      81.0  11770.28         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20) # Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Look at data information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "Upon examining the data, it's evident that every column in the dataset adheres to the appropriate data type. Additionally, initial scrutiny reveals no instances of missing values within the dataset. The data suggests that the column labeled `is_ultra` serves as a classification attribute, with a value of 1 denoting the 'ultra' plan and 0 indicating a 'smart' plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there's just one dataset available, the source data will undergo a split of 3:1:1. This allocation reserves 60% of the data for training purposes, while 20% is set aside for both validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_3_1_1(dataset, test_s=0.40, rnd_state=42):\n",
    "    '''Prints a statement specifying the data-split used and returns 3 variables for the train, validation and test datasets respectively'''\n",
    "    \n",
    "    # Splitting the source data into 40% for Validation (to be split again) and 60% for Training\n",
    "    df_train, df_valid = train_test_split(df, test_size=test_s, random_state=rnd_state)\n",
    "\n",
    "    # Further splitting the df_valid data 50/50 (40% from previous task) to obtain 3:1:1 ratio\n",
    "    df_test, df_valid = train_test_split(df_valid, test_size=(test_s + .10), random_state=rnd_state)\n",
    "    \n",
    "    # Printing confirmation of data split\n",
    "    sum_of_datasets = len(df_train) + len(df_valid) + len(df_test)\n",
    "    if len(df) == sum_of_datasets:\n",
    "        print(f\"Data split ratio is 3:1:1, where data is allocated as:\\nTraining = 60% (n={len(df_train)})\\nValidation = 20% (n={len(df_valid)})\\nTesting = 20% (n={len(df_test)})\")\n",
    "    \n",
    "    return df_train, df_valid, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split ratio is 3:1:1, where data is allocated as:\n",
      "Training = 60% (n=1928)\n",
      "Validation = 20% (n=643)\n",
      "Testing = 20% (n=643)\n"
     ]
    }
   ],
   "source": [
    "# Unpacking the values by calling function\n",
    "\n",
    "df_train, df_valid, df_test = split_data_3_1_1(df, 0.40, 24681)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset, drop_cols, target_col):\n",
    "    features = dataset.drop(drop_cols, axis=1)\n",
    "    target = dataset[target_col]\n",
    "    \n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the train, validation, and test features & target\n",
    "\n",
    "train_features, train_target = prepare_data(df_train, ['is_ultra'], 'is_ultra')\n",
    "valid_features, valid_target = prepare_data(df_valid, ['is_ultra'], 'is_ultra')\n",
    "test_features, test_target = prepare_data(df_test, ['is_ultra'], 'is_ultra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Tree Model at Various Depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model: 0.8009331259720062\n",
      "Depth of the best model: 3\n"
     ]
    }
   ],
   "source": [
    "best_model_tree = None\n",
    "best_result_tree = 0\n",
    "best_depth_tree = 0\n",
    "\n",
    "for depth in range(1,6):\n",
    "    model = DecisionTreeClassifier(random_state=24681, max_depth=depth)\n",
    "    model.fit(train_features, train_target)\n",
    "    valid_predictions = model.predict(valid_features)\n",
    "    result = accuracy_score(valid_target, valid_predictions) \n",
    "    \n",
    "    if result > best_result_tree:\n",
    "        best_model_tree = model\n",
    "        best_result_tree = result\n",
    "        best_depth_tree = depth\n",
    "\n",
    "print(f\"Accuracy of the best model: {best_result_tree}\\nDepth of the best model: {best_depth_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Random Forest at Various Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model: 0.7993779160186625\n",
      "Number of estimators of the best model: 19\n"
     ]
    }
   ],
   "source": [
    "best_model_forest = None\n",
    "best_result_forest = 0\n",
    "best_est_forest = 0\n",
    "\n",
    "for est in range(1, 20):\n",
    "    model = RandomForestClassifier(random_state=24681, n_estimators=est)\n",
    "    model.fit(train_features, train_target)\n",
    "    valid_predictions = model.predict(valid_features)\n",
    "    result = accuracy_score(valid_target, valid_predictions) \n",
    "    if result > best_result_forest:\n",
    "        best_model_forest = model\n",
    "        best_result_forest = result\n",
    "        best_est_forest = est\n",
    "        \n",
    "print(f\"Accuracy of the best model: {best_result_forest}\\nNumber of estimators of the best model: {est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Logistic Regresssion Model using 'liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.7325038880248833\n"
     ]
    }
   ],
   "source": [
    "def run_log_regression(rnd_state=42, solv='liblinear'):\n",
    "    model = LogisticRegression(random_state=rnd_state, solver=solv)\n",
    "    model.fit(train_features, train_target) \n",
    "    valid_predictions = model.predict(valid_features)\n",
    "    result = accuracy_score(valid_target, valid_predictions)\n",
    "    print(f\"Accuracy of the model: {result}\")\n",
    "    \n",
    "run_log_regression(24681)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The training data was utilized to train three distinct models:\n",
    "1. `DecisionTreeClassifier`\n",
    "2. `RandomForestClassifier`\n",
    "3. `LogisticRegression`\n",
    "\n",
    "Following this, the validation data was employed to generate predictions for each model, and the accuracy score was computed for each. It's evident that the most accurate model was the Decision Tree model trained with a depth of 3. The Random Forest model, utilizing 19 estimators, closely followed as the second most accurate model. Conversely, the Logistic Regression model performed very poorly with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of training the different models. It is clear to see that the DecisionTreeClassifier is the best model to use for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.8133748055987559\n"
     ]
    }
   ],
   "source": [
    "# Creating and training the final model\n",
    "\n",
    "final_model = DecisionTreeClassifier(random_state=24681, max_depth=3)\n",
    "final_model.fit(train_features, train_target)\n",
    "\n",
    "# Making predictions using testing data\n",
    "test_predictions = final_model.predict(test_features)\n",
    "\n",
    "# Checking accuracy using test target and test predictions\n",
    "result = accuracy_score(test_target, test_predictions)\n",
    "\n",
    "print(f\"The accuracy score is: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 120\n"
     ]
    }
   ],
   "source": [
    "def error_count(answers, predictions):\n",
    "    count = 0\n",
    "    for i in range(len(answers)):\n",
    "        if answers[i] != predictions[i]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "answers = test_target.values\n",
    "\n",
    "# Count number of errors\n",
    "print('Errors:', error_count(answers, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The final model was developed using a `DecisionTreeClassifier` algorithm. This model underwent training using the training dataset. Instead of utilizing the validation dataset for testing, the model's accuracy was assessed using a separate test dataset that had not been previously used during training or validation. The resulting accuracy score of the final model was 81.33%, with a total of 120 errors identified during testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the development of our model utilizing the DecisionTreeClassifier algorithm has proven successful. Through training on the designated dataset and subsequent evaluation on a separate, previously untouched test dataset, we achieved an impressive accuracy score of 81.33%. This outcome surpassed the targeted accuracy threshold of 75% set by Megaline for the project. During testing, a total of 120 errors were identified, providing valuable insights for further refinement and optimization of our model. This accomplishment signifies a significant step forward in leveraging subscriber behavior data to recommend appropriate plan transitions, thereby advancing Megaline's goals of enhancing subscriber satisfaction and plan adoption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
